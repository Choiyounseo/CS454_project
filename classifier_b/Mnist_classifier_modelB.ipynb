{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_classifier_modelB",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSZTHh1rLkN4",
        "colab_type": "code",
        "outputId": "47c1cb74-9b7c-4385-852e-9d3357515245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRrbi-vsLV0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        " \n",
        "batch_size = 100\n",
        " \n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        " \n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=True,\n",
        "                              transform=transform,\n",
        "                              download=True)\n",
        " \n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                             train=False,\n",
        "                             transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        " \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgQp_SiYLXmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels = 64, kernel_size=8, stride = 2, padding = 3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels = 128, kernel_size=6, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels = 128, kernel_size=5, stride = 1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.FC1 = nn.Linear(128, 10)\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = x.view(in_size, -1)\n",
        "        x = self.FC1(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO2GIr3pO9lt",
        "colab_type": "code",
        "outputId": "33cf6028-b189-4d9c-da99-8a84f0ea42b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model = Net()\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "best_acc = 0.\n",
        "ckpt_dir = os.path.join(gdrive_root, 'checkpoints')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "ckpt_path = os.path.join(ckpt_dir, 'modelB_ckpt.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path)\n",
        "    try:\n",
        "        model.load_state_dict(ckpt['model'])\n",
        "        optimizer.load_state_dict(ckpt['optimizer'])\n",
        "        best_acc = ckpt['best_acc']\n",
        "    except RuntimeError as e:\n",
        "        print('wrong checkpoint')\n",
        "    else:    \n",
        "        print('checkpoint is loaded !')\n",
        "        print('current best accuracy : %.2f' % best_acc)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(best_acc):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        \n",
        "        test_loss += criterion(output, target).item()\n",
        "        \n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = correct / float(len(test_loader.dataset))\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        ckpt = {'model': model.state_dict(),\n",
        "                'optimizer':optimizer.state_dict(),\n",
        "                'best_acc':best_acc}\n",
        "        torch.save(ckpt, ckpt_path)\n",
        "        print('checkpoint is saved!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint is loaded !\n",
            "current best accuracy : 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R49QhUgvQDiI",
        "colab_type": "code",
        "outputId": "63895558-43bf-49c2-d7c8-950ec4a98cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test(best_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.561294\n",
            "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 1.525297\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 1.569090\n",
            "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 1.538717\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.528415\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.531669\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.514713\n",
            "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 1.540260\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.602337\n",
            "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.576212\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.579537\n",
            "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.542132\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.592749\n",
            "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.575133\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.522352\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.544717\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.539533\n",
            "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.556709\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.562909\n",
            "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.548974\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.533948\n",
            "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.532931\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.582987\n",
            "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 1.557134\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.543502\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 1.559588\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.541502\n",
            "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 1.498298\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.542439\n",
            "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 1.533074\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.615302\n",
            "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 1.616909\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.567265\n",
            "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 1.574607\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.529466\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 1.554721\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.539651\n",
            "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 1.571747\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.541605\n",
            "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 1.513121\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.560641\n",
            "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 1.546839\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.531922\n",
            "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 1.538464\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.519710\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 1.597332\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.549881\n",
            "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 1.557983\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.556480\n",
            "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 1.518265\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.550627\n",
            "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 1.533776\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.523744\n",
            "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 1.550758\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.531888\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 1.529011\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.561703\n",
            "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 1.578760\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.535477\n",
            "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 1.548743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0152, Accuracy: 9482/10000 (95%)\n",
            "\n",
            "checkpoint is saved!\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.556067\n",
            "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 1.552650\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.548869\n",
            "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 1.540725\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.559685\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 1.555741\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.566243\n",
            "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 1.557468\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.564225\n",
            "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 1.553032\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.558714\n",
            "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 1.554462\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.518218\n",
            "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 1.521634\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.536335\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 1.549361\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.514958\n",
            "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 1.514863\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.548286\n",
            "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 1.532111\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.535566\n",
            "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 1.553620\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.536969\n",
            "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 1.577807\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.584570\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 1.581232\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.541066\n",
            "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 1.528528\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.569881\n",
            "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 1.517503\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.563952\n",
            "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 1.549280\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.554298\n",
            "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 1.558062\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.554378\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 1.533069\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.579966\n",
            "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 1.541543\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.575910\n",
            "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 1.551487\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.547079\n",
            "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 1.565805\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.571015\n",
            "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 1.564264\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.548420\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 1.532015\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.569587\n",
            "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 1.576947\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.547351\n",
            "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 1.580383\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.571931\n",
            "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 1.549509\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.576495\n",
            "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 1.596762\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.563857\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 1.552509\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.528569\n",
            "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 1.557162\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.522071\n",
            "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 1.547192\n",
            "\n",
            "Test set: Average loss: 0.0151, Accuracy: 9513/10000 (95%)\n",
            "\n",
            "checkpoint is saved!\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.543367\n",
            "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 1.533978\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.585806\n",
            "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 1.562224\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.527210\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 1.520943\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.522977\n",
            "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 1.556358\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.529431\n",
            "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 1.574808\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.523835\n",
            "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 1.538872\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.531186\n",
            "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 1.584791\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.591728\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 1.528106\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.526183\n",
            "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 1.543269\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.537695\n",
            "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 1.566143\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.551551\n",
            "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 1.558827\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.578095\n",
            "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 1.546816\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.535225\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 1.576401\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.534131\n",
            "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 1.594236\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.577297\n",
            "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 1.530537\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.559956\n",
            "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 1.550703\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.540354\n",
            "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 1.531541\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.563484\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 1.536755\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.497980\n",
            "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 1.561127\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.470541\n",
            "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 1.541017\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.508651\n",
            "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 1.515911\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.539695\n",
            "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 1.560345\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.528674\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 1.543185\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.527434\n",
            "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 1.528435\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.514576\n",
            "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 1.525887\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.516455\n",
            "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 1.537384\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.511624\n",
            "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 1.551870\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.546777\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 1.523995\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.583370\n",
            "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 1.551139\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.531017\n",
            "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 1.537747\n",
            "\n",
            "Test set: Average loss: 0.0151, Accuracy: 9535/10000 (95%)\n",
            "\n",
            "checkpoint is saved!\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.535379\n",
            "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 1.548801\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.557173\n",
            "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 1.530626\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.554498\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 1.557473\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.533383\n",
            "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 1.596515\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.537544\n",
            "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 1.552949\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.531322\n",
            "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 1.519384\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.548395\n",
            "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 1.530141\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.501585\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 1.519048\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.510412\n",
            "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 1.520719\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.545200\n",
            "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 1.555736\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.579889\n",
            "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 1.519434\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.552743\n",
            "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 1.536574\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.532448\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 1.536865\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.539665\n",
            "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 1.524091\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.533865\n",
            "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 1.526174\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.537235\n",
            "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 1.542229\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.547390\n",
            "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 1.520833\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.547081\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 1.526711\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.547531\n",
            "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 1.533197\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.576706\n",
            "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 1.556514\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.544559\n",
            "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 1.511055\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.515129\n",
            "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 1.515954\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.527038\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 1.559245\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 1.554720\n",
            "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 1.556944\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.567006\n",
            "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 1.550167\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.543034\n",
            "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 1.542403\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 1.525070\n",
            "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 1.507963\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.525343\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 1.506051\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.550948\n",
            "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 1.523595\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 1.514177\n",
            "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 1.519776\n",
            "\n",
            "Test set: Average loss: 0.0151, Accuracy: 9558/10000 (96%)\n",
            "\n",
            "checkpoint is saved!\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.517653\n",
            "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 1.541305\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 1.511185\n",
            "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 1.530803\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 1.534741\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 1.528677\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 1.529572\n",
            "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 1.585131\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.506693\n",
            "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 1.510282\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.538910\n",
            "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 1.526694\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 1.560038\n",
            "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 1.519426\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 1.517938\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 1.544098\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.533345\n",
            "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 1.537822\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 1.511755\n",
            "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 1.555484\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.511487\n",
            "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 1.537932\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 1.535908\n",
            "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 1.574264\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.523985\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 1.514031\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 1.527766\n",
            "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 1.600432\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 1.526495\n",
            "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 1.525503\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.518093\n",
            "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 1.528933\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.531265\n",
            "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 1.557897\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 1.551871\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 1.524200\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 1.513717\n",
            "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 1.527214\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 1.503025\n",
            "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 1.489095\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.543966\n",
            "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 1.524889\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 1.532708\n",
            "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 1.521145\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 1.540884\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 1.472422\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 1.542159\n",
            "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 1.536421\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.518964\n",
            "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 1.555943\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.536535\n",
            "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 1.507464\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 1.543580\n",
            "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 1.533477\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 1.493589\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 1.540506\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 1.552150\n",
            "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 1.557509\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 1.526538\n",
            "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 1.564263\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy: 9606/10000 (96%)\n",
            "\n",
            "checkpoint is saved!\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.544258\n",
            "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 1.522808\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 1.508782\n",
            "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 1.505773\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 1.518188\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 1.567784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-aa51ee3a901f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-5b4ec82163a7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRmPYFvvQeW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}