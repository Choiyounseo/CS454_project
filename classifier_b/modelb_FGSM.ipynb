{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelb_FGSM",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS_Btw_YRZX7",
        "colab_type": "code",
        "outputId": "d4325c59-d7fd-4ded-f128-be5aa263ccb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'\n",
        "gdrive_data = '/gdrive/My Drive/my_data'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vhz2mCaRzie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda=True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "batch_size = 1\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                             train=False,\n",
        "                             transform=transforms.ToTensor(),\n",
        "                              download=True)\n",
        " \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaVezGuIR7m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels = 64, kernel_size=8, stride = 2, padding = 3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels = 128, kernel_size=6, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels = 128, kernel_size=5, stride = 1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.FC1 = nn.Linear(128, 10)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = x.view(in_size, -1)\n",
        "        x = self.FC1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yqxKwwFSAzc",
        "colab_type": "code",
        "outputId": "3344b527-55fe-4f65-f050-8d4968a88564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "\n",
        "model = Net()\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "ckpt_dir = os.path.join(gdrive_root, 'checkpoints')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "  print(\"error...\")\n",
        "\n",
        "ckpt_path = os.path.join(ckpt_dir, 'modelB_ckpt.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "  ckpt = torch.load(ckpt_path)\n",
        "  try:\n",
        "    model.load_state_dict(ckpt['model'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer'])\n",
        "    best_acc = ckpt['best_acc']\n",
        "  except RuntimeError as e:\n",
        "    print('wrong checkpoint')\n",
        "  else:    \n",
        "    print('checkpoint is loaded !')\n",
        "    print('current best accuracy : %.2f' % best_acc)\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint is loaded !\n",
            "current best accuracy : 0.98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (relu): ReLU()\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2))\n",
              "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (FC1): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwAeZ72RSEj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PayIHVVNSG1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test( model, test_loader, epsilon ):\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        # print( target)\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            # if len(adv_examples) < 1000:\n",
        "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "              adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rTj8pPpSKGF",
        "colab_type": "code",
        "outputId": "be15f8ae-a659-4e8f-ed0e-eba26d329585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, test_loader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 9768 / 10000 = 0.9768\n",
            "Epsilon: 0.05\tTest Accuracy = 9341 / 10000 = 0.9341\n",
            "Epsilon: 0.1\tTest Accuracy = 8179 / 10000 = 0.8179\n",
            "Epsilon: 0.15\tTest Accuracy = 5554 / 10000 = 0.5554\n",
            "Epsilon: 0.2\tTest Accuracy = 2420 / 10000 = 0.242\n",
            "Epsilon: 0.25\tTest Accuracy = 928 / 10000 = 0.0928\n",
            "Epsilon: 0.3\tTest Accuracy = 360 / 10000 = 0.036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_3gmtqwSMZs",
        "colab_type": "code",
        "outputId": "41c4c45d-2d33-4ee1-b541-f3f4a46331e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "\n",
        "for i in range(len(examples)) :\n",
        "  print(len(examples[i]))\n",
        "#print(examples[-1][0])\n",
        "plt.figure(figsize=(8,10))\n",
        "plt.imshow(examples[-1][0][-1], cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9768\n",
            "427\n",
            "1589\n",
            "4214\n",
            "7348\n",
            "8840\n",
            "9408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHdCAYAAADFMKrmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 576x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAowLabsVaiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A Tensor to a PIL image\n",
        "def imsave(data, save=None): \n",
        "  # w, h = 512, 512\n",
        "  I8 = (((data - data.min()) / (data.max() - data.min())) * 255.9).astype(np.uint8)\n",
        "  pil_img = Image.fromarray(I8)\n",
        "  pil_img.save(save)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5i38NxrXvlN",
        "colab_type": "code",
        "outputId": "a966463a-cbcd-4385-be79-0cb949998fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "for i in range(len(epsilons)):\n",
        "    print(epsilons[i])\n",
        "    for j in range(20):\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        imsave(ex, save=gdrive_data+'/{}_{}to{}.jpg'.format(epsilons[i], orig, adv))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.05\n",
            "0.1\n",
            "0.15\n",
            "0.2\n",
            "0.25\n",
            "0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8TNhQ4oZZ65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}