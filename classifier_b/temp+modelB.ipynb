{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS454_kh",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV_L2TreOf20",
        "colab_type": "code",
        "outputId": "a981a160-b87e-4dde-91e0-ba7b8dcb6b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pip install deap"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/98/3166fb5cfa47bf516e73575a1515734fe3ce05292160db403ae542626b32/deap-1.3.0-cp36-cp36m-manylinux2010_x86_64.whl (151kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deap) (1.17.4)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1CHtYKOh9L",
        "colab_type": "code",
        "outputId": "500d45c7-4f4f-4459-a939-d8709777fb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjvciXzvO0fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, nc, nz, ngf):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 7, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 7 x 7\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 7 x 7\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 14 x 14\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 14 x 14\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 28 x 28\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Classifier_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier_B, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels = 64, kernel_size=8, stride = 2, padding = 3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels = 128, kernel_size=6, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels = 128, kernel_size=5, stride = 1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.FC1 = nn.Linear(128, 10)\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = x.view(in_size, -1)\n",
        "        x = self.FC1(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def get_output(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = x.view(in_size, -1)\n",
        "        x = self.FC1(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xouVIMrtOdq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils as utils\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torch.autograd import Variable\n",
        "import glob\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "from deap import creator, base, tools, algorithms\n",
        "import os\n",
        "\n",
        "# Hyper parameters\n",
        "params = {\n",
        "\t'input_size': 28,  # image size 1x64x64\n",
        "\t'batch_size': 64,  # batch size\n",
        "\t'r': 10,   # population size\n",
        "\t'L': 50,  # number of iterations\n",
        "\t'nc': 1,  # number of channels\n",
        "\t'nz': 100,  # size of z latent vector\n",
        "\t'ngf': 64,  # size of feature maps in generator\n",
        "\t'ndf': 32,  # size of feature maps in discriminator\n",
        "\t'num_epochs': 1000,  # number of epochs\n",
        "\t'lr': 0.0001,  # learning rate\n",
        "\t'beta1': 0.5,   # beta1 for adam optimizer\n",
        "\t'ngpu': 1,  # number of GPU\n",
        "\t'lambda_gp': 10,  # loss weight for gradient penalty\n",
        "\t'n_critic': 5,\n",
        "}\n",
        "\n",
        "model_weight_path = './data/weights/netG_12500.pth'\n",
        "classifier_weight_path = './classifiers/checkpoint'\n",
        "netG = None\n",
        "MSE_loss = nn.MSELoss()\n",
        "\n",
        "# transform\n",
        "transform = transforms.Compose([transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "\n",
        "def imshow(img):\n",
        "\timg = (img + 1) / 2\n",
        "\timg = img.squeeze()\n",
        "\tnp_img = img.numpy()\n",
        "\tplt.imshow(np_img, cmap='gray')\n",
        "\tplt.show()\n",
        "\n",
        "def imshow_images(rec_rr, zs, netG):\n",
        "\tfig = plt.figure()\n",
        "\tfor i in range(rec_rr):\n",
        "\t\timg = netG(zs[i]).detach()\n",
        "\t\timg = (img + 1) / 2\n",
        "\t\timg = img.squeeze()\n",
        "\t\tnp_img = img.numpy()\n",
        "\t\tax = fig.add_subplot(1,rec_rr,i+1)\n",
        "\t\tax.imshow(np_img)\n",
        "\tplt.show()\n",
        "\n",
        "def defensegan(x, observation_change=False, observation_step=100):\n",
        "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\tx = x.view(28, 28).numpy().astype(np.float64)\n",
        "\tinitial_population = torch.FloatTensor(params['r'], params['nz'], 1, 1).normal_(0, 1)\n",
        "\tinitial_population = initial_population.view(params['r'], params['nz']).numpy()\n",
        "\tdef evalFunc(individual):\n",
        "\t\tindividual = torch.from_numpy(individual).view(1, params['nz'], 1, 1)\n",
        "\t\tfitness = np.linalg.norm(netG(individual).view(28, 28).detach().numpy() - x, ord=2) ** 2,\n",
        "\t\treturn fitness\n",
        "\tdef initIndividual(icls, content):\n",
        "\t\treturn icls(content)\n",
        "\tdef initPopulation(pcls, ind_init):\n",
        "\t\treturn pcls(ind_init(c) for c in initial_population)\n",
        "\tcreator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "\tcreator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMin)  # minimizing the fitness value\n",
        "\ttoolbox = base.Toolbox()\n",
        "\tIND_SIZE = params['nz']\n",
        "\tPOPULATION = params['r']\n",
        "\tCXPB, MUTPB = 0.4, 0.2\n",
        "\tGENERATIONS = params['L']\n",
        "\ttoolbox.register(\"attr_float\", random.random)\n",
        "\ttoolbox.register(\"individual\", initIndividual, creator.Individual)\n",
        "\ttoolbox.register(\"population\", initPopulation, list, toolbox.individual)\n",
        "\ttoolbox.register(\"evaluate\", evalFunc)\n",
        "\ttoolbox.register(\"mate\", tools.cxUniform, indpb=0.1)\n",
        "\ttoolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.1)\n",
        "\ttoolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "\trandom.seed(777)\n",
        "\n",
        "\t# pop = toolbox.population(n=POPULATION)\n",
        "\tpop = toolbox.population()\n",
        "\n",
        "\tprint(\"Start of evolution\")\n",
        "\n",
        "\t# Evaluate the entire population\n",
        "\t# print(fitnesses) -> [(84,), (105,), (96,), (104,), (94,),  ... ] 이런식으로 저장됨.\n",
        "\tfitnesses = list(map(toolbox.evaluate, pop))\n",
        "\tfor ind, fit in zip(pop, fitnesses):\n",
        "\t\tind.fitness.values = fit\n",
        "\n",
        "\t# Extracting all the fitnesses of\n",
        "\tfits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "\t# Variable keeping track of the number of generations\n",
        "\tg = 0\n",
        "\n",
        "\t# Begin the evolution\n",
        "\twhile min(fits) > 10 and g < GENERATIONS:\n",
        "\t\t# A new generation\n",
        "\t\tg = g + 1\n",
        "\n",
        "\t\t# Select the next generation individuals\n",
        "\t\t# len(pop) -> 50, len(pop[0]) -> 5\n",
        "\t\toffspring = toolbox.select(pop, len(pop))\n",
        "\n",
        "\t\t# Clone the selected individuals\n",
        "\t\toffspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "\t\t# Apply crossover and mutation on the offspring\n",
        "\t\t'''\n",
        "        they modify those individuals within the toolbox container \n",
        "        and we do not need to reassign their results.\n",
        "        '''\n",
        "\t\t# TODO: want p_new1 = p_m - beta(p_m - p_d), p_new2 = p_m + beta(p_m - p_d)\n",
        "\t\t# want to customize mutation method... there is no proper mutation operator in deap.tools...\n",
        "\n",
        "\t\tfor child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "\t\t\tif random.random() < CXPB:\n",
        "\t\t\t\tsize = min(len(child1), len(child2))\n",
        "\t\t\t\tfor i in range(5):\n",
        "\t\t\t\t\tcxpoint = random.randint(2, size - 1)\n",
        "\t\t\t\t\tmtpoint = cxpoint - 1\n",
        "\t\t\t\t\t# cxpoint -1 위치 : mutate\n",
        "\t\t\t\t\tbeta = random.random()\n",
        "\t\t\t\t\tchild1[mtpoint] = child1[mtpoint] - beta * (child1[mtpoint] - child2[mtpoint])\n",
        "\t\t\t\t\tchild2[mtpoint] = child1[mtpoint] + beta * (child1[mtpoint] - child2[mtpoint])\n",
        "\n",
        "\t\t\t\t# crossover : one point crossover (temporary crossover algorithm)\n",
        "\t\t\t\t# child1[cxpoint:], child2[cxpoint:] = child2[cxpoint:], child1[cxpoint:]\n",
        "\t\t\t\tdel child1.fitness.values\n",
        "\t\t\t\tdel child2.fitness.values\n",
        "\n",
        "\t\tfor child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "\t\t\tif random.random() < CXPB:\n",
        "\t\t\t\ttoolbox.mate(child1, child2)\n",
        "\t\t\t\tdel child1.fitness.values\n",
        "\t\t\t\tdel child2.fitness.values\n",
        "\n",
        "\t\tfor mutant in offspring:\n",
        "\t\t\tif random.random() < MUTPB:\n",
        "\t\t\t\ttoolbox.mutate(mutant)\n",
        "\t\t\t\tdel mutant.fitness.values\n",
        "\n",
        "\t\t# Evaluate the individuals with an invalid fitness\n",
        "\t\tinvalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "\t\tfitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "\t\tfor ind, fit in zip(invalid_ind, fitnesses):\n",
        "\t\t\tind.fitness.values = fit\n",
        "\n",
        "\t\t# The population is entirely replaced by the offspring\n",
        "\t\tpop[:] = offspring\n",
        "\n",
        "\t\t# Gather all the fitnesses in one list and print the stats\n",
        "\t\tfits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "\t\tlength = len(pop)\n",
        "\t\tmean = sum(fits) / length\n",
        "\t\tsum2 = sum(x * x for x in fits)\n",
        "\t\tstd = abs(sum2 / length - mean ** 2) ** 0.5\n",
        "\n",
        "\t\tif g % 1 == 0:\n",
        "\t\t\tprint(\"-- Generation %i --\" % g)\n",
        "\t\t\tprint(\"  Min %s\" % min(fits))\n",
        "\t\t\tprint(\"  Max %s\" % max(fits))\n",
        "\t\t\tprint(\"  Avg %s\" % mean)\n",
        "\t\t\tprint(\"  Std %s\" % std)\n",
        "\t\t\tbest_ind = tools.selBest(pop, 1)[0]\n",
        "\t\t\tz = torch.from_numpy(best_ind).view(1, 100, 1, 1)\n",
        "\t\t\tgen_image = netG(z)\n",
        "\t\t\t# imshow(gen_image.detach())\n",
        "\n",
        "\tprint(\"-- End of (successful) evolution --\")\n",
        "\n",
        "\tbest_ind = tools.selBest(pop, 1)[0]\n",
        "\tz = torch.from_numpy(best_ind).view(1, 100, 1, 1)\n",
        "\tgen_image = netG(z)\n",
        "\timshow(gen_image.detach())\n",
        "\treturn gen_image\n",
        "\n",
        "def main():\n",
        "\t# Generator(ngpu, nc, nz, ngf)\n",
        "  global netG\n",
        "  netG = Generator(params['ngpu'], params['nc'], params['nz'], params['ngf'])\n",
        "  netG.load_state_dict(torch.load(gdrive_root + '/checkpoints/netG_12500.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "\t# Classifier\n",
        "  classifier_b = Classifier_B()\n",
        "  classifier_b.load_state_dict(torch.load('/gdrive/My Drive/checkpoints/modelB_ckpt.pt')['model'])\n",
        "  classifier_b.eval()\n",
        "\n",
        "\t# available epsilon values : 0.1, 0.2, 0.3, 0.05, 0.15, 0.25\n",
        "  epsilon_set = [0.1, 0.2, 0.3, 0.05, 0.15, 0.25]\n",
        "  acc_defense_gan = [0] * 6  # accuracy of defense GAN\n",
        "  acc_classifier_b = [0] * 6  # accuracy of classifier b\n",
        "  total = [0] * 6  # number of fgsm images for each epsilon\n",
        "  correct_defense_gan = [0] * 6  # number of fgsm images correctly classified for each epsilon by defense gan\n",
        "  correct_classifier_b = [0] * 6  # number of fgsm images correctly classified for each epsilon by classifier b\n",
        "\n",
        "  for file_path in glob.glob(\"/gdrive/My Drive/classifier_b_fgsm_small_sample/*.jpg\"):\n",
        "    #for file_path in glob.glob(\"./data/fgsm_images_a/*.jpg\"):  # fgsm images from classifier a (fgsm_images_a)\n",
        "\t\t# get epsilon and ground truth by parsing\n",
        "    #print(file_path[48:])\n",
        "    temp_file_path = file_path[48:]\n",
        "    file_name = temp_file_path.split('_')\n",
        "    epsilon = float(file_name[0])\n",
        "    ground_truth = float(file_name[1])\n",
        "    fgsm_truth = float(file_name[3])\n",
        "    print('This fgsm image is originally ' + str(int(ground_truth)) + ', misclassified as ' +\n",
        "\t\t\t  str(int(fgsm_truth)) + ' with epsilon ' + str(epsilon))\n",
        "    fgsm_image = Image.open(file_path)\n",
        "    fgsm_image = TF.to_tensor(fgsm_image)\n",
        "    #fgsm_image = transform(fgsm_image)  # torch.Size([1, 28, 28])\n",
        "    imshow(fgsm_image)\n",
        "    #print(fgsm_image)\n",
        "    #break\n",
        "    # do defense gan\n",
        "    result_image = defensegan(fgsm_image)  # return type tensor [1, 1, 28, 28]. image G(z) that has minimum fitness\n",
        "    # to classify image\n",
        "    outputs_defense_gan = classifier_b(result_image)\n",
        "    outputs_classifier_b = classifier_b(fgsm_image.view(1, 1, params['input_size'], params['input_size']))\n",
        "    prediction_defense_gan = torch.max(outputs_defense_gan.data, 1)[1]\n",
        "    prediction_classifier_b = torch.max(outputs_classifier_b.data, 1)[1]\n",
        "    #print('output from defense gan is ' + str(outputs_defense_gan))\n",
        "    #print('output from classifier is ' + str(outputs_classifier_b))\n",
        "    print('defense gan classified fgsm image (' + str(ground_truth) + ' to ' + str(fgsm_truth) +\n",
        "        ') as ' + str(prediction_defense_gan.item()))\n",
        "    print('classifier b classified fgsm image (' + str(ground_truth) + ' to ' + str(fgsm_truth) +\n",
        "        ') as ' + str(prediction_classifier_b.item()))\n",
        "    epsilon_index = epsilon_set.index(epsilon)  # returns the index of epsilon from epsilon_set\n",
        "    total[epsilon_index] += 1\n",
        "    if prediction_defense_gan.item() == ground_truth:\n",
        "      print('prediction from defense gan correct!')\n",
        "      correct_defense_gan[epsilon_index] += 1\n",
        "    if prediction_classifier_b.item() == ground_truth:\n",
        "      print('prediction from classifier correct! - this should not happen...')\n",
        "      correct_classifier_b[epsilon_index] += 1\n",
        "    break\n",
        "    print('total # images for each epsilon : ' + str(total))\n",
        "    print('correct defense gan : ' + str(correct_defense_gan))\n",
        "    print('correct classifier b : ' + str(correct_classifier_b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK72O0SoP5Uz",
        "colab_type": "code",
        "outputId": "3919f602-6820-431e-95d6-89aba696a5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This fgsm image is originally 0, misclassified as 3 with epsilon 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt5+vghWao00AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Start of evolution\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- Generation 1 --\n",
            "  Min 30.310498830193712\n",
            "  Max 69.4214921879759\n",
            "  Avg 43.562921995681116\n",
            "  Std 14.055143491309053\n",
            "-- Generation 2 --\n",
            "  Min 30.310498830193712\n",
            "  Max 70.06876425374793\n",
            "  Avg 35.84225372007749\n",
            "  Std 11.516277466075323\n",
            "-- Generation 3 --\n",
            "  Min 30.127709968863\n",
            "  Max 32.33937331162695\n",
            "  Avg 30.95482223702275\n",
            "  Std 0.8340879660373212\n",
            "-- Generation 4 --\n",
            "  Min 29.674454662439345\n",
            "  Max 32.14544906497983\n",
            "  Avg 30.335626294598136\n",
            "  Std 0.6358118909963257\n",
            "-- Generation 5 --\n",
            "  Min 29.10541364199549\n",
            "  Max 30.312642966555654\n",
            "  Avg 29.960820216172202\n",
            "  Std 0.35610912025976793\n",
            "-- Generation 6 --\n",
            "  Min 28.983492860811936\n",
            "  Max 30.209535347744765\n",
            "  Avg 29.736534266865682\n",
            "  Std 0.4231139437429797\n",
            "-- Generation 7 --\n",
            "  Min 28.51655477962248\n",
            "  Max 30.236674991601934\n",
            "  Avg 29.4396402711075\n",
            "  Std 0.5626243769237277\n",
            "-- Generation 8 --\n",
            "  Min 28.539957229445623\n",
            "  Max 29.82616729600891\n",
            "  Avg 29.133454597250477\n",
            "  Std 0.4810854991893426\n",
            "-- Generation 9 --\n",
            "  Min 28.539957229445623\n",
            "  Max 29.58089543996525\n",
            "  Avg 28.80233621936045\n",
            "  Std 0.38565042031551644\n",
            "-- Generation 10 --\n",
            "  Min 28.22279048419317\n",
            "  Max 29.498798471557294\n",
            "  Avg 28.62981884968852\n",
            "  Std 0.31179374838793206\n",
            "-- Generation 11 --\n",
            "  Min 28.082651107616808\n",
            "  Max 28.56636745425219\n",
            "  Avg 28.396902273376988\n",
            "  Std 0.15943813158761683\n",
            "-- Generation 12 --\n",
            "  Min 27.992457794378595\n",
            "  Max 28.5624229185589\n",
            "  Avg 28.27128223726612\n",
            "  Std 0.18659170631141905\n",
            "-- Generation 13 --\n",
            "  Min 27.971611511256377\n",
            "  Max 28.22279048419317\n",
            "  Avg 28.11561687155872\n",
            "  Std 0.09297060744885134\n",
            "-- Generation 14 --\n",
            "  Min 27.971611511256377\n",
            "  Max 28.408086388358562\n",
            "  Avg 28.065602916551132\n",
            "  Std 0.121995799774679\n",
            "-- Generation 15 --\n",
            "  Min 27.971611511256377\n",
            "  Max 28.041951887893596\n",
            "  Avg 28.00104220447181\n",
            "  Std 0.01836823383807932\n",
            "-- Generation 16 --\n",
            "  Min 27.524163419305104\n",
            "  Max 28.74869247634202\n",
            "  Avg 28.012899649972905\n",
            "  Std 0.2808296783748591\n",
            "-- Generation 17 --\n",
            "  Min 27.486635575899168\n",
            "  Max 27.97960980653656\n",
            "  Avg 27.835124840840983\n",
            "  Std 0.21243318529514518\n",
            "-- Generation 18 --\n",
            "  Min 27.398598710816213\n",
            "  Max 27.971611511256377\n",
            "  Avg 27.681190767580212\n",
            "  Std 0.23900232805237345\n",
            "-- Generation 19 --\n",
            "  Min 27.02441514585435\n",
            "  Max 27.52228598798956\n",
            "  Avg 27.43222468632407\n",
            "  Std 0.1430989661127914\n",
            "-- Generation 20 --\n",
            "  Min 26.762088996157132\n",
            "  Max 27.71153876994895\n",
            "  Avg 27.24779729198594\n",
            "  Std 0.3253715542781877\n",
            "-- Generation 21 --\n",
            "  Min 26.762088996157132\n",
            "  Max 27.26398668501063\n",
            "  Avg 26.978101039862786\n",
            "  Std 0.13658858711268895\n",
            "-- Generation 22 --\n",
            "  Min 26.679727042583224\n",
            "  Max 27.082988287974853\n",
            "  Avg 26.894962963977086\n",
            "  Std 0.14246012601888036\n",
            "-- Generation 23 --\n",
            "  Min 26.679727042583224\n",
            "  Max 27.339819430631447\n",
            "  Avg 26.92182759095787\n",
            "  Std 0.24427163943275446\n",
            "-- Generation 24 --\n",
            "  Min 26.011839020568054\n",
            "  Max 27.02441514585435\n",
            "  Avg 26.624935071024805\n",
            "  Std 0.29505242453282826\n",
            "-- Generation 25 --\n",
            "  Min 24.71154402283361\n",
            "  Max 26.94234547143959\n",
            "  Avg 26.334473219800913\n",
            "  Std 0.5863092804435176\n",
            "-- Generation 26 --\n",
            "  Min 25.285443591053955\n",
            "  Max 26.53658159360724\n",
            "  Avg 26.293827412546637\n",
            "  Std 0.38777711043991686\n",
            "-- Generation 27 --\n",
            "  Min 25.076462842147983\n",
            "  Max 26.15945746095106\n",
            "  Avg 25.74586857072171\n",
            "  Std 0.3778989487208533\n",
            "-- Generation 28 --\n",
            "  Min 25.076462842147983\n",
            "  Max 26.230853316908288\n",
            "  Avg 25.592457555631945\n",
            "  Std 0.3700702781545292\n",
            "-- Generation 29 --\n",
            "  Min 24.655795888492015\n",
            "  Max 25.285443591053955\n",
            "  Avg 25.050013271541655\n",
            "  Std 0.14711447409714717\n",
            "-- Generation 30 --\n",
            "  Min 24.119993014097812\n",
            "  Max 25.371491753084122\n",
            "  Avg 24.881713902060532\n",
            "  Std 0.3710272046577171\n",
            "-- Generation 31 --\n",
            "  Min 24.119993014097812\n",
            "  Max 25.23343811255276\n",
            "  Avg 24.76399804326238\n",
            "  Std 0.3746168746341454\n",
            "-- Generation 32 --\n",
            "  Min 24.07550825143439\n",
            "  Max 25.07780656133762\n",
            "  Avg 24.419881819203177\n",
            "  Std 0.342679810234454\n",
            "-- Generation 33 --\n",
            "  Min 23.99883637397063\n",
            "  Max 24.47037750712975\n",
            "  Avg 24.18962306877352\n",
            "  Std 0.15806574619121128\n",
            "-- Generation 34 --\n",
            "  Min 23.99650303269816\n",
            "  Max 24.194696671087765\n",
            "  Avg 24.067152479178603\n",
            "  Std 0.058057759378270214\n",
            "-- Generation 35 --\n",
            "  Min 23.794016501879668\n",
            "  Max 24.07550825143439\n",
            "  Avg 23.997683709656272\n",
            "  Std 0.07295708166404961\n",
            "-- Generation 36 --\n",
            "  Min 23.794016501879668\n",
            "  Max 24.166888089349477\n",
            "  Avg 23.935736628209572\n",
            "  Std 0.12099237043912815\n",
            "-- Generation 37 --\n",
            "  Min 23.145441541005155\n",
            "  Max 24.166888089349477\n",
            "  Avg 23.797762745343785\n",
            "  Std 0.24793204450327613\n",
            "-- Generation 38 --\n",
            "  Min 23.145441541005155\n",
            "  Max 23.794016501879668\n",
            "  Avg 23.529168359364043\n",
            "  Std 0.31365746562887226\n",
            "-- Generation 39 --\n",
            "  Min 22.89846913313702\n",
            "  Max 23.791315278473146\n",
            "  Avg 23.238194159949888\n",
            "  Std 0.2694399107505393\n",
            "-- Generation 40 --\n",
            "  Min 22.870928838459935\n",
            "  Max 23.336328823685562\n",
            "  Avg 23.06095501899079\n",
            "  Std 0.12186540385688964\n",
            "-- Generation 41 --\n",
            "  Min 22.831016268302225\n",
            "  Max 23.052652614558323\n",
            "  Avg 22.974828365857523\n",
            "  Std 0.08400981758555191\n",
            "-- Generation 42 --\n",
            "  Min 22.637351872797847\n",
            "  Max 23.035118615765406\n",
            "  Avg 22.86451342977088\n",
            "  Std 0.09619424880482642\n",
            "-- Generation 43 --\n",
            "  Min 22.637351872797847\n",
            "  Max 22.931007514213135\n",
            "  Avg 22.82659836719612\n",
            "  Std 0.08584655031689059\n",
            "-- Generation 44 --\n",
            "  Min 22.637351872797847\n",
            "  Max 22.863715489366104\n",
            "  Avg 22.76613538832353\n",
            "  Std 0.09499735754880025\n",
            "-- Generation 45 --\n",
            "  Min 22.599904124664576\n",
            "  Max 22.830811573847974\n",
            "  Avg 22.66495544237706\n",
            "  Std 0.062145883465704585\n",
            "-- Generation 46 --\n",
            "  Min 22.56276038493857\n",
            "  Max 22.655353115955453\n",
            "  Avg 22.62224911213523\n",
            "  Std 0.026910029518099114\n",
            "-- Generation 47 --\n",
            "  Min 22.562096536161157\n",
            "  Max 22.677477270942948\n",
            "  Avg 22.601902767818263\n",
            "  Std 0.0373852340456111\n",
            "-- Generation 48 --\n",
            "  Min 22.51415005457223\n",
            "  Max 22.57551450121867\n",
            "  Avg 22.5597712741502\n",
            "  Std 0.016172826235542177\n",
            "-- Generation 49 --\n",
            "  Min 22.51572210187846\n",
            "  Max 22.56276038493857\n",
            "  Avg 22.555798700793297\n",
            "  Std 0.013410752965077074\n",
            "-- Generation 50 --\n",
            "  Min 22.37009524432585\n",
            "  Max 22.74233503460224\n",
            "  Avg 22.57153677996064\n",
            "  Std 0.08718557472509522\n",
            "-- End of (successful) evolution --\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTjDsRE4w7EROMOxETvwNaYOY8Up/P/kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "defense gan classified fgsm image (0.0 to 3.0) as 0\n",
            "classifier b classified fgsm image (0.0 to 3.0) as 3\n",
            "prediction from defense gan correct!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8Gu--zoSPW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}