{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BZrb3knlLqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "74ac3245-9a52-489e-94da-a55ab5d0a915"
      },
      "source": [
        "pip install deap"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/98/3166fb5cfa47bf516e73575a1515734fe3ce05292160db403ae542626b32/deap-1.3.0-cp36-cp36m-manylinux2010_x86_64.whl (151kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deap) (1.17.4)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6KCDNJNmCqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c55bd644-7f1e-4e91-abe6-000cfd773bf3"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwXRTu0KldZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, nc, nz, ngf):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 7, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 7 x 7\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 7 x 7\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 14 x 14\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 14 x 14\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 28 x 28\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r02KmvHGmKJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f70e51f-ed74-435b-9597-bc79082df48b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as utils\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def imshow(img):\n",
        "    img = (img + 1) / 2\n",
        "    img = img.squeeze()\n",
        "    np_img = img.numpy()\n",
        "    plt.imshow(np_img, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "def imshow_grid(img):\n",
        "    img = utils.make_grid(img.cpu().detach())\n",
        "    img = (img + 1) / 2\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Hyper parameters\n",
        "params = {\n",
        "    'input_size': 28,  # image size 1x64x64\n",
        "    'batch_size': 64,  # batch size\n",
        "    'pop_size': 100,   # population size\n",
        "    'nc': 1,  # number of channels\n",
        "    'nz': 100,  # size of z latent vector\n",
        "    'ngf': 64,  # size of feature maps in generator\n",
        "    'ndf': 32,  # size of feature maps in discriminator\n",
        "    'num_epochs': 1000,  # number of epochs\n",
        "    'lr': 0.0001,  # learning rate\n",
        "    'beta1': 0.5,   # beta1 for adam optimizer\n",
        "    'ngpu': 1,  # number of GPU\n",
        "    'lambda_gp': 10,  # loss weight for gradient penalty\n",
        "    'n_critic': 5,\n",
        "}\n",
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Generator(ngpu, nc, nz, ngf)\n",
        "# 이 부분에서 체크포인트 위치 설정.\n",
        "netG = Generator(params['ngpu'], params['nc'], params['nz'], params['ngf'])\n",
        "netG.load_state_dict(torch.load(gdrive_root + '/checkpoints/netG_12500.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "# transform\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "# data sets and data loader\n",
        "train_data = datasets.MNIST(root='data/', train=True, transform=transform, download=True)\n",
        "train_data_loader = DataLoader(train_data, params['batch_size'], shuffle=False)\n",
        "first_batch = train_data_loader.__iter__().__next__()  # first batch of MNIST data set : torch.Size([64x, 1, 28, 28])\n",
        "print(first_batch[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "#imshow(first_batch[0][0])  # plot the image of first batch"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "navWYmQBsJUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3107a436-5895-4491-bf16-a758b88f8988"
      },
      "source": [
        "import random\n",
        "from deap import creator, base, tools, algorithms\n",
        "\n",
        "# TOCHECK:  will we use algorithm modules?\n",
        "\n",
        "'''\n",
        "Fitness : single optimization, minimize ||G(z) - x||^2_2\n",
        "'''\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMin) # minimizing the fitness value\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "'''\n",
        "[HYPERPARAMETERS]\n",
        "List of Floats: individuals composed of 'IND_SIZE' floating point numbers\n",
        "IND_SIZE: z의 dimension으로 보면 될듯\n",
        "POPULATION\n",
        "CXPB: probability of crossover\n",
        "MUTPB: probability of mutation\n",
        "'''\n",
        "IND_SIZE = 100\n",
        "POPULATION = 100\n",
        "CXPB, MUTPB = 0.2, 0.2\n",
        "GENERATIONS = 100\n",
        "\n",
        "toolbox.register(\"attr_float\", random.random)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=IND_SIZE)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "def cxTwoPointCopy(ind1, ind2):\n",
        "    \"\"\"Execute a two points crossover with copy on the input individuals. The\n",
        "    copy is required because the slicing in numpy returns a view of the data,\n",
        "    which leads to a self overwritting in the swap operation. It prevents\n",
        "    ::\n",
        "    \n",
        "        >>> import numpy\n",
        "        >>> a = numpy.array((1,2,3,4))\n",
        "        >>> b = numpy.array((5,6,7,8))\n",
        "        >>> a[1:3], b[1:3] = b[1:3], a[1:3]\n",
        "        >>> print(a)\n",
        "        [1 6 7 4]\n",
        "        >>> print(b)\n",
        "        [5 6 7 8]\n",
        "    \"\"\"\n",
        "    size = len(ind1)\n",
        "    cxpoint1 = random.randint(1, size)\n",
        "    cxpoint2 = random.randint(1, size - 1)\n",
        "    if cxpoint2 >= cxpoint1:\n",
        "        cxpoint2 += 1\n",
        "    else: # Swap the two cx points\n",
        "        cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n",
        "\n",
        "    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] \\\n",
        "        = ind2[cxpoint1:cxpoint2].copy(), ind1[cxpoint1:cxpoint2].copy()\n",
        "        \n",
        "    return ind1, ind2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kb7nChgmRDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "bb2bd29f-979e-4a3c-b40e-f0db902812d2"
      },
      "source": [
        "# Input image for defense GAN\n",
        "# For the test purpose, we will use MNIST data sample first.\n",
        "# fgsm_image : torch.Size([1, 28, 28]). This is image x.\n",
        "fgsm_image = first_batch[0][0]  # torch.Size([1, 28, 28]). This should be fgsm_image later on.\n",
        "\n",
        "# evalFunc 에서 numpy 형태로 계산하려고 모양 수정 / 일단은 그냥 28, 28로 했는데 나중엔 일렬로 계산해도 될 듯.\n",
        "x = fgsm_image.view(28,28).numpy()\n",
        "#imshow(fgsm_image)\n",
        "\n",
        "# individual은 numpy array\n",
        "# numpy array 가 들어오면 -> tensor로 바꾸고, netG input 모양에 맞춰줌.\n",
        "# netG의 output이 tensor 형태이므로, numpy로 바꿔서 계산.. (이부분 텐서 형태에서 계산으로 추후 수정하면 될 듯.)\n",
        "def evalFunc(individual):\n",
        "    individual = torch.from_numpy(individual).view(1, 100, 1, 1)\n",
        "    return np.linalg.norm(netG(individual).view(28, 28).detach().numpy() - x, ord=2)**2\n",
        "\n",
        "# Initial population for GA\n",
        "# initial_population : torch.Size([100, 100, 1, 1]), This has 100 latent vectors z (z is torch.Size([100, 1, 1])).\n",
        "# for example, initial_population[0] is z_0, initial_population[1] is z_1, ..., initial_population[99] is z_99.\n",
        "initial_population = torch.FloatTensor(params['pop_size'], params['nz'], 1, 1).normal_(0, 1)\n",
        "#print(initial_population.shape)  # torch.Size([100, 100, 1, 1])\n",
        "\n",
        "\n",
        "# 이 부분은 evalFunc 이 잘 작동하는지 확인하는 부분입니당.\n",
        "# z 가 길이 100짜리 1차원 numpy array 라고 가정하고(GA 에서 기본 individual 형태) evalFunc에 넣은뒤, 출력\n",
        "z = torch.FloatTensor(1, params['nz'], 1, 1).normal_(0, 1)\n",
        "z = z.view(100).numpy()\n",
        "print(evalFunc(z))\n",
        "\n",
        "# initial_population를 numpy로 타입 맞춰주기.\n",
        "initial_population = initial_population.view(100, 100).numpy()\n",
        "\n",
        "#########################\n",
        "# Do the GA from here!! # or gradient descent\n",
        "#########################\n",
        "# Thought : manipulating latent vectors is important since domain is specified (z is normal dist.)\n",
        "# and, GA should have high converging power.\n",
        "\n",
        "# For each generation, select the latent vector z* that minimizes fitness, and do the following.\n",
        "z = torch.FloatTensor(1, params['nz'], 1, 1).normal_(0, 1)  # torch.Size([100, 1, 1]). This should be z* later on.\n",
        "print(\"the shape of latent vector : \" + str(z.shape))\n",
        "gen_image = netG(z)  # torch.Size([1, 28, 28]). This is the generated image that we want to see for each generation.\n",
        "# Because gen_image should step closer to fgsm_image x for each generation.\n",
        "print(\"the shape of generated image : \" + str(gen_image.shape))\n",
        "imshow(gen_image.detach())  # plot the image of generated image\n",
        "\n",
        "# After GA, give generated image as input to each classifier (use gen_image)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "194.0220860870113\n",
            "[[-0.26212975 -0.22245978 -1.1557736  ... -1.2895316   0.8864686\n",
            "   0.08005337]\n",
            " [-0.10363276  1.8579419   1.8164245  ... -0.49195328  2.1127563\n",
            "  -1.1015389 ]\n",
            " [ 0.2393099  -0.8281347   0.4849926  ...  0.369192   -0.11912449\n",
            "   1.9289007 ]\n",
            " ...\n",
            " [ 0.00963861 -0.990944   -0.7005533  ...  0.44421026 -0.06784059\n",
            "  -0.6683479 ]\n",
            " [ 0.7677108  -0.13975468 -0.82682866 ... -0.21326618  1.9265594\n",
            "   0.01750526]\n",
            " [-0.21674751  0.80773485 -0.16027735 ...  1.0120332   1.6141067\n",
            "  -0.39148426]]\n",
            "the shape of latent vector : torch.Size([1, 100, 1, 1])\n",
            "the shape of generated image : torch.Size([1, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgRB2IEgCDsQBGEHgiDsQBD/Cwndqh2F5XVpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcvP72m-q2h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}