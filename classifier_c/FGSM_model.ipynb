{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FGSM_model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkBVt4_ClJJ5",
        "colab_type": "code",
        "outputId": "301c6277-b08f-424a-aeb0-5aeb2631b17a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# !rm -r /gdrive/*\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'\n",
        "gdrive_data = '/gdrive/My Drive/my_data/CS454_modelC'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRrbi-vsLV0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda=True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "batch_size = 1\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                             train=False,\n",
        "                             transform=transforms.ToTensor(),\n",
        "                              download=True)\n",
        " \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgQp_SiYLXmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batchnorm1 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels = 128, kernel_size=3, stride = 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=128, out_channels = 64, kernel_size=3, stride = 2, padding=2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.FC1 = nn.Linear(64*15*15, 128)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.FC2 = nn.Linear(128, 10)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.relu(self.conv1(x)) \n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 64*15*15)\n",
        "        x = self.relu(self.FC1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.FC2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6SjLkh6lR_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "0b60602f-79df-4283-9780-0931764eba98"
      },
      "source": [
        "model = Net()\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "ckpt_dir = os.path.join(gdrive_root, 'checkpoints')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "  print(\"error...\")\n",
        "\n",
        "ckpt_path = os.path.join(ckpt_dir, 'modelC_ckpt.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "  ckpt = torch.load(ckpt_path)\n",
        "  try:\n",
        "    model.load_state_dict(ckpt['model'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer'])\n",
        "    best_acc = ckpt['best_acc']\n",
        "  except RuntimeError as e:\n",
        "    print('wrong checkpoint')\n",
        "  else:    \n",
        "    print('checkpoint is loaded !')\n",
        "    print('current best accuracy : %.2f' % best_acc)\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint is loaded !\n",
            "current best accuracy : 0.97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (relu): ReLU()\n",
              "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
              "  (dropout1): Dropout(p=0.25, inplace=False)\n",
              "  (FC1): Linear(in_features=14400, out_features=128, bias=True)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (FC2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE4cCOlIrLBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO2GIr3pO9lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test( model, test_loader, epsilon ):\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        # print( target)\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            # if len(adv_examples) < 1000:\n",
        "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "              adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R49QhUgvQDiI",
        "colab_type": "code",
        "outputId": "fd63f8a1-b117-463d-c36f-bf759da94785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, test_loader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 9726 / 10000 = 0.9726\n",
            "Epsilon: 0.05\tTest Accuracy = 9385 / 10000 = 0.9385\n",
            "Epsilon: 0.1\tTest Accuracy = 7873 / 10000 = 0.7873\n",
            "Epsilon: 0.15\tTest Accuracy = 4354 / 10000 = 0.4354\n",
            "Epsilon: 0.2\tTest Accuracy = 2149 / 10000 = 0.2149\n",
            "Epsilon: 0.25\tTest Accuracy = 1038 / 10000 = 0.1038\n",
            "Epsilon: 0.3\tTest Accuracy = 453 / 10000 = 0.0453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25Mo0U2r-nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A Tensor to a PIL image\n",
        "def imsave(data, save=None): \n",
        "  # w, h = 512, 512\n",
        "  I8 = (((data - data.min()) / (data.max() - data.min())) * 255.9).astype(np.uint8)\n",
        "  pil_img = Image.fromarray(I8)\n",
        "  pil_img.save(save)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opI1pCIKx5CV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt = 0\n",
        "plt.figure(figsize=(8,10))\n",
        "for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "        cnt += 1\n",
        "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if j == 0:\n",
        "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        plt.title(\"{} -> {}\".format(orig, adv))\n",
        "        plt.imshow(ex, cmap=\"gray\")\n",
        "        if (i == len(epsilons)-1) and (j == len(examples[i])-1):\n",
        "          plt.savefig(gdrive_data+'/final.jpg')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yEzfp2br_w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save all generated adversarial images\n",
        "for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        imsave(ex, save=gdrive_data+'/{}-{}to{}.jpg'.format(epsilons[i], orig, adv))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}